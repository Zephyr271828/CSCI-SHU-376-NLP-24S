{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5BVolBz4eAM"
      },
      "source": [
        "# Homework 1\n",
        "# Natural Language Processing, CSCI-SHU376 Spring 2024\n",
        "\n",
        "## Due Feb 25, 2024 at 11:59pm China Time\n",
        "\n",
        "Name: Yufeng Xu\n",
        "\n",
        "NetID: yx3038\n",
        "\n",
        "Please submit the following items to Gradescope:\n",
        "* Your Colab notebook link (by clicking the Share button at the top-right corner of the Colab notebook, share to anyone).\n",
        "* The printout of your run in Colab notebook in pdf format\n",
        "\n",
        "Note:\n",
        "* late submission is allowed, following our 72hr policy.\n",
        "* All solutions must be from your own work.\n",
        "* Total points of the assignment is 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u42nnKCp9zTB"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VYTazUFx74y",
        "outputId": "0bb34c24-00b8-44a2-85ed-ed6ab0397092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kf17w56x_PJ",
        "outputId": "9d9b4653-a2e8-4455-a4a5-da6d5c57221b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: HOME=/content/drive/My Drive/\n",
            "/content/drive/My Drive/Courses/nlp_spring2024/homework1\n"
          ]
        }
      ],
      "source": [
        "# This makes your Google drive as the HOME directory in Colab\n",
        "%env HOME=/content/drive/My Drive/\n",
        "# This folder will be used to store your models and results\n",
        "!mkdir -p ~/Courses/nlp_spring2024/homework1/\n",
        "%cd ~/Courses/nlp_spring2024/homework1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeGEn4oXb0CF",
        "outputId": "17d32b38-4ddf-4043-d5cb-ef17634cfab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: joblib in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from nltk) (1.1.1)\n",
            "Requirement already satisfied: click in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
            "Collecting dill<0.3.8,>=0.3.0\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=8.0.0\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-macosx_10_15_x86_64.whl (27.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.1/27.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow-hotfix\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (2023.10.0)\n",
            "Requirement already satisfied: packaging in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (1.26.1)\n",
            "Requirement already satisfied: filelock in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (3.12.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-macosx_10_9_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: aiohttp in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (3.8.3)\n",
            "Collecting huggingface-hub>=0.19.4\n",
            "  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, nltk, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.17.3\n",
            "    Uninstalling huggingface-hub-0.17.3:\n",
            "      Successfully uninstalled huggingface-hub-0.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.16.1 dill-0.3.7 huggingface-hub-0.20.3 multiprocess-0.70.15 nltk-3.8.1 pyarrow-15.0.0 pyarrow-hotfix-0.6 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS8C-k9LsxwY"
      },
      "source": [
        "# 1. N-gram LM with ADD-one smoothing [50 pts]\n",
        "\n",
        "Add-one smoothing is a method to smooth the N-gram counts. Please refer to the lecture slides for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHjJmlwf7_i7"
      },
      "source": [
        "##__a__. Implement `class ADD1LM`. [50 pts]\n",
        "\n",
        "In this question, you will implement ADD-ONE LM.\n",
        "\n",
        "The ADD-ONE LM `class ADD1LM` support the following functions:\n",
        "* Select the top-K vocabulary based on the `min_count` on the training data. If `min_count` is 1, all vocabulary will be selected from the training data.\n",
        "* Calculate raw N-gram counts from a dataset.\n",
        "* Estimate LM model parameters: with add-one smoothing\n",
        "* Calculate word perplexity on a dataset.\n",
        "* Generate random sentences using the LM.\n",
        "\n",
        "All word tokens that are not in the selected vocabulary should be mapped to `<unk>`, the unknown word token.\n",
        "\n",
        "### Dataset\n",
        "We use the datasets module from Huggingface to load the Penntree bank text data for LM experiment. Example of getting an iterable over sentences is shown in `class ADD1LM`.\n",
        "\n",
        "### Limited usage of NLTK\n",
        "We allow using `nltk.ngrams` to compute the ngrams given a list of word tokens. But you are NOT allowed to use any other functions and data structures in nltk for this assignment.\n",
        "\n",
        "### Data structure\n",
        "Please use the provided data structure to complete the task. We assume using the Python dictionaries to store the discounted probs and backoff weights, as provided in `class ADD1LM`.\n",
        "\n",
        "Context: A tuple of strings\n",
        "\n",
        "word: A string\n",
        "\n",
        "order 1: unigram, order 2: bigram and so forth.\n",
        "\n",
        "For example:\n",
        "\n",
        "`self._prob[1][context=()][word=\"is\"]` stores the probs P*(\"is\") for unigram (N-gram order = 1).\n",
        "\n",
        "`self._prob[2][context=(\"this\",)][word=\"is\"]` stores the probs probs P*(\"is\"|\"this\") for bigrams (N-gram order = 2).\n",
        "\n",
        "`self._prob[3][context=(\"this\",\"is\",)][word=\"a\"]` stores the probs P*(\"a\"|\"this is\") for trigrams (N-gram order = 3).\n",
        "\n",
        "We also provide a data structure to store the N-gram counts in `self.counters`.\n",
        "\n",
        "Alternatively, you may also use other Python data structure as you see fit to store the LM parameters.\n",
        "\n",
        "### Correctness\n",
        "All the estimated probabilities of *any* context must sum to 1.0. You may use `def check_lm()` and `def check_prob()` to check the correctness by trying out some word context at different N-gram orders. You should carefully check the validity of your LM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z9NkJnB9G17U"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/zephyr/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import datasets\n",
        "import multiprocessing\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "class SimpleTokenizer:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def tokenize(self, sentence): ####### the implementation of tokenizer\n",
        "    return sentence.strip().split()\n",
        "\n",
        "class ADD1LM:\n",
        "  def __init__(self, order, min_count, tokenizer):\n",
        "    \"\"\"\n",
        "    order: integer. order = 1...N\n",
        "    min_count: at least 1\n",
        "    tokenizer: tokenize a given sentence strin\n",
        "    \"\"\"\n",
        "    self._bos = \"<s>\" # begin of sentence\n",
        "    self._eos = \"</s>\" # end of sentence\n",
        "    self._unk = \"<unk>\" # word not in vocabulary\n",
        "\n",
        "    # set class variables\n",
        "    self._order = order\n",
        "    self._min_count = min_count\n",
        "    self._tokenizer = tokenizer\n",
        "\n",
        "    # data structures for the LM\n",
        "    # prob\n",
        "    self._prob = [defaultdict(lambda: defaultdict(float)) for i in range(order+1)]\n",
        "\n",
        "    # data structure to store the N-gram counts\n",
        "    self._counters = [defaultdict(lambda: defaultdict(float)) for i in range(order+1)]\n",
        "\n",
        "    # vocabulary set\n",
        "    self._vocab = set()\n",
        "\n",
        "  def print_counter(self, counter):\n",
        "    \"\"\"\n",
        "    Debugging purpose: You may want to print the counters based on only a handful of sentences\n",
        "    and see if the computed counts are equal to the ones computed by hand.\n",
        "    \"\"\"\n",
        "    for context in counter.keys():\n",
        "      for word in counter[context].keys():\n",
        "        print(\"{} {} {}\".format(context, word, counter[context][word]))\n",
        "\n",
        "  def _select_vocab(self, dataset, min_count):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    print('Selecting vocabulary...')\n",
        "    counter = defaultdict(int)\n",
        "    for sample in dataset:\n",
        "      tokens = self._tokenizer.tokenize(sample['sentence'])\n",
        "\n",
        "    # TODO: Your code\n",
        "      for word in tokens:\n",
        "        counter[word] += 1\n",
        "        \n",
        "      for word in counter.keys():\n",
        "        if counter[word] >= min_count:\n",
        "          self._vocab.add(word.lower())\n",
        "    self._vocab.add(self._bos)\n",
        "    self._vocab.add(self._eos)\n",
        "    #print(self._bos in self._vocab)\n",
        "    #print(self._eos in self._vocab)\n",
        "    #print(self._unk in self._vocab)\n",
        "      \n",
        "    print(\"Size of vocabulary is {}\".format(len(self._vocab)))\n",
        "\n",
        "  def compute_count(self, dataset, order):\n",
        "    \"\"\"\n",
        "    dataset: iterable yielding a dictionary object that has a field 'sentence'\n",
        "    order: integer. order = 1...N\n",
        "    counter is just a dictionary of a dictionary of a integer\n",
        "    counter[context][word] stores the raw N-gram counts\n",
        "    \"\"\"\n",
        "    counter = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for sample in dataset:\n",
        "      tokens = self._tokenizer.tokenize(sample['sentence'])\n",
        "\n",
        "      # map word not in vocab to <unk>\n",
        "      # TODO: Your code\n",
        "      for i in range(len(tokens)):\n",
        "        if tokens[i] not in self._vocab:\n",
        "          tokens[i] = self._unk\n",
        "      \n",
        "      # a generator of N-gram tuples\n",
        "      text_ngrams = nltk.ngrams(tokens, n=order, pad_left=True, pad_right=True, left_pad_symbol=self._bos, right_pad_symbol=self._eos)\n",
        "      for each in list(text_ngrams):\n",
        "        counter[each[:-1]][each[-1]] += 1\n",
        "\n",
        "    return counter\n",
        "\n",
        "  def compute_prob(self, context, word, order):\n",
        "    \"\"\"\n",
        "    context: tuple of string\n",
        "    word: string\n",
        "    \"\"\"\n",
        "    p = 0.0\n",
        "    beta = 1\n",
        "    # TODO: Your code\n",
        "    if order > 1 and context != (self._bos,):\n",
        "      p = (self._counters[order][context][word] + beta) / (self._counters[order - 1][context[:-1]][context[-1]] + len(self._vocab) * beta)\n",
        "    else:\n",
        "      p = (self._counters[order][context][word] + beta) / (sum(self._counters[order][context].values()) + len(self._vocab) * beta)\n",
        "    #print(f'Context: {context} Word: {word} Prob: {p}')\n",
        "    return p\n",
        "\n",
        "  def train(self, dataset):\n",
        "    \"\"\"\n",
        "    Train a LM.\n",
        "    dataset: an iterable object\n",
        "    \"\"\"\n",
        "    # select vocab by taking the top-K\n",
        "    print(\"estimating vocabulary set with mincount = {}\".format(self._min_count))\n",
        "    self._select_vocab(dataset, self._min_count)\n",
        "\n",
        "    # compute the raw count of the highest N-order\n",
        "    #print(\"Compute raw count for order {}\".format(self._order))\n",
        "    #self._counters[self._order] = self.compute_count(dataset, self._order)\n",
        "\n",
        "    # TODO: Your Code:\n",
        "    # Use the member functions to complete the training steps\n",
        "    for o in range(1, self._order + 1):\n",
        "\n",
        "      print(f'Computing raw count for order {o}...')\n",
        "      self._counters[o] = self.compute_count(dataset, o)\n",
        "\n",
        "      print(f'Computing probability for order {o}...')\n",
        "      for context in tqdm(self._counters[o].keys()):\n",
        "        for word in self._vocab:\n",
        "          self._prob[o][context][word] = self.compute_prob(context, word, o)\n",
        "\n",
        "  def perplexity(self, dataset):\n",
        "    \"\"\"\n",
        "    Given a test file that contains a list of sentences line-by-line, read all lines and\n",
        "    compute word perplexity of the test file.\n",
        "    Please do not change the code here as it is for evaluation for all students.\n",
        "    \"\"\"\n",
        "    log_prob = 0.0\n",
        "    N = 0.0\n",
        "    for sample in dataset:\n",
        "      tokens = self._tokenizer.tokenize(sample['sentence'])\n",
        "\n",
        "      # map word not in vocab to <unk>\n",
        "      tokens = [w if w in self._vocab else self._unk for w in tokens]\n",
        "\n",
        "      # N-grams of sentence\n",
        "      text_ngrams = nltk.ngrams(tokens, n=self._order, pad_left=True, pad_right=True, left_pad_symbol=self._bos, right_pad_symbol=self._eos)\n",
        "\n",
        "      # x is a tuple of N-gram tokens\n",
        "      for x in text_ngrams:\n",
        "        context, word = x[:-1], x[-1]\n",
        "        p = self.compute_prob(context, word, self._order)\n",
        "        if p < 1e-10:\n",
        "          print(\"ERROR: small prob for {} {} {}\".format(\" \".join(context), word, p))\n",
        "        else:\n",
        "          log_prob += math.log(p)\n",
        "          N += 1\n",
        "    \n",
        "    return math.exp(-log_prob / N)\n",
        "\n",
        "  def generate(self):\n",
        "    \"\"\"\n",
        "    Generate a random sentence using the trained LM.\n",
        "    Return a sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    context = [self._bos] * (self._order-1)\n",
        "    result = []\n",
        "\n",
        "    # TODO: Your code\n",
        "    # Think about how each token is generated from a LM given a context. This involves\n",
        "    # sampling a word from your LM.\n",
        "    while 1:\n",
        "      candidates = self._prob[self._order][tuple(context)]\n",
        "      k = 4\n",
        "      top_k = sorted(candidates, key = lambda x : self._prob[self._order][tuple(context)][x], reverse = True)[:k]\n",
        "      #p = [self._prob[self._order][tuple(context)][x] for x in top_k]\n",
        "      #print(top_5)\n",
        "      #print(p)\n",
        "      choice = random.choice(top_k)\n",
        "      while choice == self._unk:\n",
        "        choice = random.choice(top_k)\n",
        "      if choice == self._eos:\n",
        "        break\n",
        "      result.append(choice)\n",
        "      context = context[1:] + [choice]\n",
        "    \n",
        "    return \" \".join(result)\n",
        "\n",
        "  def check_prob(self, context, order):\n",
        "    \"\"\"\n",
        "    This is for checking whether your LM behaves properly on each word context.\n",
        "    \"\"\"\n",
        "    z = 0.0\n",
        "    for word in self._vocab:\n",
        "      if word != self._bos:\n",
        "        z += self.compute_prob(context, word, order)\n",
        "\n",
        "    epsilon = 1e-4\n",
        "    if z < 1 - epsilon or z > 1 + epsilon:\n",
        "      print(z)\n",
        "      print(sum(self._counters[order][context].values()))\n",
        "      print(self._counters[order - 1][context[:-1]][context[-1]])\n",
        "      print(\"Prob sum check failed at order {} for context {}!\".format(order, context))\n",
        "      return False\n",
        "    return True\n",
        "\n",
        "  def check_lm(self):\n",
        "    \"\"\"\n",
        "    This is for checking whether your LM behaves properly on each word context.\n",
        "    \"\"\"\n",
        "    # check 1-gram prob, should sum to 1!\n",
        "    #self.check_prob((), 1)\n",
        "\n",
        "    # check high-order prob\n",
        "    for o in range(1, self._order+1):\n",
        "      print(f'Checking probability for order {o}...')\n",
        "      for i, context in enumerate(self._prob[o].keys()):\n",
        "        self.check_prob(context, o)\n",
        "        if i >= 1000: break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKa9-tSblPTL"
      },
      "source": [
        "### Main *program*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f0f4e1c86ec414f88ae27a4dc971098",
            "fdb73ab8b02f42f38024f1a34c002c10",
            "a8c853d6856c4c5496fcbcee027b9588",
            "314f4dc695934b0abac326ece02f3036",
            "c05ff0791d9e4aabab70d4c9c38f49cc",
            "33875da710664c689a91c2a61e043c2f",
            "1c3b5dc0a92741b7a4220947a21c3a5c",
            "8d544bacd73d4fa2b67d18eeda77e3ae",
            "f873281c739741f89d268ad4b1b130c8",
            "bc11d7cc3d8148b8a2c10e21cb419bad",
            "28126a98dd674352a5f39c458e5726e3",
            "e28d4b71cde54919979976989a6b9f66",
            "225cafeb1683440b8c56cebcf5176a30",
            "14250df929f240bdaae083b2d4fee179",
            "032f847d06494ba89d75e2bb04b6f816",
            "f230dfbb592a4e569293ea556b289c4d",
            "246e08963f1e42c0827a0b6bcf1d8020",
            "290f947a094346f6bd61c65d14ac5c86",
            "f977764c671b460eacd89d8e577a0ebc",
            "6446102077754fe99411d837a5d95b7a",
            "45fb69c53b3d498899e2ba0aa1cd4b74",
            "d956397732b74785abafa2b04c2f78f0",
            "37f993fdfead46eca86fbbc0a1c6c7c9",
            "c1b9c52c9f204f23b982c546cca4a5bd",
            "438184da8742414690c0701f13cc63e0",
            "38bdd891d2c549288e62400af5a868d6",
            "cb6e3aa3b0c848e0a85ae58ce99e2165",
            "af9c70857fd4461c9275e64d2edf7060",
            "5c46fe678117498abf4fec3a63042efc",
            "9f79fb4014ba4e18bd11cb9c8385727f",
            "6298823d67b74b27903207eb82c40089",
            "a9f9d9fd7a434da388c3b4d854f38c15",
            "750807425efa4f31b2ed2b4e2d545ccd",
            "83f78ed4b7834c90b122ec6372df8b23",
            "0afa528dfa6e466c8c770fb715bdf7f5",
            "58c64d5a28734da9bcb88b4d76ebbd5a",
            "6338deac29274431bfa21e8fdb908378",
            "b31b6bd4f5aa45afa89a90454ec8e7ed",
            "c1bd913aafa24aa9a66fb8788ef725db",
            "851670b1d0cd4bd9a04531c597de65a9",
            "ebf3244702b3476fbeaf7f659852d05d",
            "6830e40963224a95af9afc2b5f558731",
            "adcbf968d503466e94bd0996e698dcc1",
            "519490b9c61a45fcaf9ca30fb98b3ca8",
            "a1553160957c4fc0a77329eaa7ead63e",
            "a2133356ddc746b6ae578ca290b1167e",
            "7f5f28c95840437db9d8e1d674c1d551",
            "d8483392e73e4c789becb519dfc3b330",
            "ed9144f0aa194605b00c60567c4794a6",
            "b8cb5168b143442f8b5e298199a7936b",
            "efe11a12fee04deabefa51935993f073",
            "27ca92810a5e40c9b1dbbae2c98a62f7",
            "8e5dc2128cb7497dbafd6cb943c67b0c",
            "32c92f30bcaf4328a048dda7327bc15c",
            "de1cab1f50df4c72a08c88ef84c467f0",
            "6ec9825fd1bc4b71a63d8245b5ec0dec",
            "d7ff0e8ec8ce4f5aad9df6f201cfc234",
            "3424d6c236d84d6f8a4a4af1a6727ecc",
            "62fee8e94fe44b39882767e9d0833647",
            "83a61a7f8bd946179c1bce59f3dad52a",
            "81188557c7c7485a995da290abc91e4c",
            "5b93033e0fa64a2589d043359463c787",
            "2003fe223063495c8ab909cb450d482c",
            "3de2ddb357344862b70205b2e922b088",
            "a827c81ef3ce4264ba578489d2c15ef7",
            "ec8bd89b0aa549f38c782ced72166fc4"
          ]
        },
        "id": "b_2bL0Shk7mg",
        "outputId": "4772d2cc-5daf-4b1e-fca6-3c745f94da02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 25 12:01:03 CST 2024\n",
            "estimating vocabulary set with mincount = 1\n",
            "Selecting vocabulary...\n",
            "Size of vocabulary is 10001\n",
            "Computing raw count for order 1...\n",
            "Computing probability for order 1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing raw count for order 2...\n",
            "Computing probability for order 2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9999/9999 [01:16<00:00, 130.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking probability for order 1...\n",
            "Checking probability for order 2...\n",
            "Training perplexity = 677.5237127695859\n",
            "Validation perplexity = 845.9791270087259\n",
            "Test perplexity = 813.9470974138362\n"
          ]
        }
      ],
      "source": [
        "# print the timestamp (Please do not remove)\n",
        "!date\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dataset = load_dataset(\"ptb_text_only\")\n",
        "    lm = ADD1LM(order=2, min_count=1, tokenizer=SimpleTokenizer())\n",
        "    lm.train(dataset['train'])\n",
        "\n",
        "    # check probs for all orders. should sum to 1.0 in any context\n",
        "    lm.check_lm()\n",
        "\n",
        "    train_ppl = lm.perplexity(dataset['train'])\n",
        "    valid_ppl = lm.perplexity(dataset['validation'])\n",
        "    test_ppl = lm.perplexity(dataset['test'])\n",
        "\n",
        "    print(\"Training perplexity = {}\".format(train_ppl)) # Expect: ~78\n",
        "    print(\"Validation perplexity = {}\".format(valid_ppl)) # Expect: ~208\n",
        "    print(\"Test perplexity = {}\".format(test_ppl)) # Expect: ~192"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6k2skIQtSkig"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['sentence'],\n",
            "    num_rows: 42068\n",
            "})\n",
            "{'sentence': Value(dtype='string', id=None)}\n",
            "42068\n",
            "{'sentence': 'aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter'}\n",
            "{'sentence': \"plans that give advertisers discounts for maintaining or increasing ad spending have become permanent <unk> at the news <unk> and underscore the fierce competition between newsweek time warner inc. 's time magazine and <unk> b. <unk> 's u.s. news & world report\"}\n",
            "{'sentence': 'at cray computer he will be paid $ N'}\n"
          ]
        }
      ],
      "source": [
        "# look at some sentence\n",
        "print(dataset['train'])\n",
        "print(dataset['train'].features)\n",
        "print(dataset['train'].num_rows)\n",
        "print(dataset['train'][0])\n",
        "print(dataset['train'][100])\n",
        "print(dataset['train'][200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBYL_GYyz2bg"
      },
      "source": [
        "##__d__. Use your model to generate 10 sentences. Can you comment on the\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "quality of the generated sentences? [5 pts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VTZOhS0LSEh5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 25 12:03:56 CST 2024\n",
            "In new york stock\n",
            "The new company is the u.s.\n",
            "The u.s.\n",
            "In a share from the company is n't be able gradually a share in a $ sharing to the company 's largest in new company is a $ finished lower\n",
            "In new york\n",
            "But they are the company 's a share in the u.s. and the new jersey and the company 's largest cable operator 's stock\n",
            "But the company is the new company is a year earlier this month the new company 's a $ 300-a-share $ 300-a-share buy-out\n",
            "The company 's a share from $ sharing of $ sharing a share from $ finished with a year ago and a year ago when he says mr. noriega was the new york and a share in a share a share in a share\n",
            "But he says\n",
            "But the new jersey 's stock market for a year ago\n"
          ]
        }
      ],
      "source": [
        "# print the timestamp (Please do not remove)\n",
        "!date\n",
        "\n",
        "# TODO: Your code\n",
        "for i in range(10):\n",
        "    res = lm.generate()\n",
        "    print(res.capitalize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWh80lpMz7W5"
      },
      "source": [
        "**Your answer**: \n",
        "\n",
        "The generated sentences demonstrate good diversity as I used top-3 sampling, but the fluency is poor because we only used a 2-gram model, which has poor representation of the larger semantic context.\n",
        "\n",
        "Also, I excluded the unknown tokens when generating the sentences to reduce ambiguity of the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLWCstCkFQlF"
      },
      "source": [
        "# 2. Multinomial Logistic Regression [50 pts]\n",
        "In this question, we will focus on intent classification using the banking corpora which are available via the Huggingface dataset library.\n",
        "This dataset is composed of 10003 training samples and 3080\n",
        "test samples. There are 77 intents in the data. You can view the data from the provided codes below.\n",
        "\n",
        "In Part I of the exercise, we provided code that loads the dataset using `datasets.load_dataset` and\n",
        "divides the original training data into our training set and validation set in the ratio of 9:1, so that you can use the validation set for hyper-parameter model tuning. As always, you should not tune on the test set for fair reporting of test results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT5PszD-AYDR"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "n4hP-ysF7ilW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (2.16.1)\n",
            "Requirement already satisfied: nltk in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (3.8.1)\n",
            "Requirement already satisfied: scikit-learn in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (1.2.1)\n",
            "Requirement already satisfied: pandas in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (1.26.1)\n",
            "Requirement already satisfied: multiprocess in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (2023.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: filelock in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (3.12.4)\n",
            "Requirement already satisfied: pyarrow-hotfix in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: aiohttp in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: packaging in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from datasets) (15.0.0)\n",
            "Requirement already satisfied: click in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from nltk) (1.1.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /Users/zephyr/opt/anaconda3/envs/myenv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets nltk scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3QPd8gEIFQlW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/zephyr/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/zephyr/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from collections import Counter\n",
        "import operator\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "english_stopwords = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8b1SRqmAvxl"
      },
      "source": [
        "## Some of the Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "collapsed": true,
        "id": "ie20Px7wFQlZ"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "vocab_size = 64000 # number N-gram features in the vocabulary base\n",
        "num_epochs = 100 # number epoch to train\n",
        "batch_size = 16\n",
        "ngram_n = 1 # the n in n-gram\n",
        "num_class = 77 # Number of intents in banking77 corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJUZfN0gjw3E"
      },
      "source": [
        "##Part I: Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "wvv1OUbWa68n"
      },
      "outputs": [],
      "source": [
        "#Data Loading from Huggingface\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "data = load_dataset(\"banking77\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3yx7LMQbP-g"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['train', 'test'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg6UkxjiHUjQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 10003\n",
            "})\n",
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 3080\n",
            "})\n",
            "[159, 110, 126, 87, 127, 171, 181, 156, 157, 129, 59, 153, 112, 139, 112, 187, 168, 167, 61, 177, 160, 122, 86, 35, 129, 153, 173, 133, 182, 121, 121, 121, 112, 118, 166, 137, 126, 97, 106, 129, 98, 82, 121, 120, 105, 159, 143, 149, 148, 115, 95, 162, 169, 161, 129, 108, 111, 114, 114, 145, 97, 146, 103, 175, 172, 113, 171, 128, 102, 104, 113, 126, 41, 135, 121, 180, 163]\n"
          ]
        }
      ],
      "source": [
        "print(data['train'])\n",
        "print(data['test'])\n",
        "label_dist = [0] * num_class\n",
        "for k in data['train']['label']:\n",
        "  label_dist[k] += 1\n",
        "print(label_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoD75hT7DsTt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': ['I am still waiting on my card?', \"What can I do if my card still hasn't arrived after 2 weeks?\", 'I have been waiting over a week. Is the card still coming?'], 'label': [11, 11, 11]}\n"
          ]
        }
      ],
      "source": [
        "print(data['train'][:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KwNnl7G_FQla"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9002\n",
            "1001\n",
            "3080\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "TRAIN_SIZE = int(len(data[\"train\"]) * 0.9)\n",
        "VALIDATION_SIZE = len(data[\"train\"]) - TRAIN_SIZE\n",
        "TEST_SIZE = len(data[\"test\"])\n",
        "PADDING_IDX = 0\n",
        "print(TRAIN_SIZE)\n",
        "print(VALIDATION_SIZE)\n",
        "print(TEST_SIZE)\n",
        "print(english_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zTsEjCkh9iq"
      },
      "outputs": [],
      "source": [
        "class Datum():\n",
        "    \"\"\"\n",
        "    Class that represents a train/validation/test datum\n",
        "    - self.raw_text\n",
        "    - self.label\n",
        "    - self.tokens: list of tokens\n",
        "    - self.token_idx: index of each token in the text\n",
        "    \"\"\"\n",
        "    def __init__(self, raw_text, label):\n",
        "        self.raw_text = raw_text\n",
        "        self.label = label\n",
        "\n",
        "    def set_ngram(self, ngram_ctr):\n",
        "        self.ngram = ngram_ctr\n",
        "\n",
        "    def set_token_idx(self, token_idx):\n",
        "        self.token_idx = token_idx\n",
        "\n",
        "    def set_tokens(self, tokens):\n",
        "        self.tokens = tokens\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Function that cleans the string\n",
        "    \"\"\"\n",
        "    text = text.lower().replace(\"<br />\", \" \")\n",
        "    return text\n",
        "\n",
        "def create_dataset(data):\n",
        "  output = []\n",
        "  for i in range(len(data['label'])):\n",
        "    output.append(Datum(preprocess_text(data['text'][i]),data['label'][i]))\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OWXAZl3e-_1"
      },
      "outputs": [],
      "source": [
        "shuffle = np.random.RandomState(seed=42).permutation(TRAIN_SIZE + VALIDATION_SIZE)\n",
        "TRAIN_ID = shuffle[:TRAIN_SIZE]\n",
        "VAL_ID = shuffle[TRAIN_SIZE:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QjLluDBa-CZ"
      },
      "outputs": [],
      "source": [
        "trainset = create_dataset(data['train'][TRAIN_ID])\n",
        "valset = create_dataset(data['train'][VAL_ID])\n",
        "testset = create_dataset(data['test'][:TEST_SIZE])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3D-kANUbTAf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is it possible for me to change my pin number? 21\n",
            "i'm not sure why my card didn't work 25\n",
            "defaultdict(<class 'int'>, {21: 101, 25: 133, 59: 134, 15: 171, 5: 157, 27: 116, 34: 150, 53: 144, 7: 139, 17: 153, 57: 105, 60: 94, 24: 119, 6: 158, 69: 94, 12: 98, 4: 116, 39: 116, 74: 111, 54: 114, 76: 152, 47: 132, 19: 152, 48: 135, 32: 105, 29: 111, 13: 124, 45: 140, 20: 145, 52: 150, 11: 140, 38: 98, 73: 116, 28: 162, 30: 109, 70: 100, 75: 165, 63: 160, 40: 91, 64: 153, 18: 51, 66: 147, 35: 123, 56: 97, 61: 139, 46: 124, 3: 82, 23: 31, 16: 150, 51: 145, 37: 89, 31: 113, 72: 37, 58: 96, 33: 115, 9: 122, 67: 117, 2: 113, 8: 141, 50: 81, 65: 100, 71: 115, 43: 105, 1: 96, 41: 76, 26: 158, 55: 97, 14: 100, 0: 143, 22: 75, 68: 96, 49: 104, 36: 116, 62: 93, 42: 108, 44: 92, 10: 52}) 9002\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# dump label counts for train set\n",
        "train_label_cnt = defaultdict(int)\n",
        "for i, sample in enumerate(trainset):\n",
        "  x,y = sample.raw_text, sample.label\n",
        "  if i < 2:\n",
        "    print(x, y)\n",
        "  train_label_cnt[y] += 1\n",
        "print(train_label_cnt, len(trainset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZjVMrmujDW2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "there is a payment with my card which i definitely did not make by me .never seen that it before. 16\n",
            "can i see where my money came from? 70\n",
            "defaultdict(<class 'int'>, {16: 18, 70: 13, 59: 11, 24: 10, 43: 15, 58: 18, 1: 14, 17: 14, 5: 14, 73: 19, 63: 15, 37: 8, 7: 17, 66: 24, 26: 15, 28: 20, 38: 8, 56: 14, 19: 25, 54: 15, 40: 7, 6: 23, 69: 10, 23: 4, 74: 10, 64: 19, 2: 13, 45: 19, 48: 13, 20: 15, 0: 16, 11: 13, 25: 20, 29: 10, 46: 19, 71: 11, 36: 10, 75: 15, 32: 7, 55: 11, 51: 17, 8: 16, 21: 21, 15: 16, 30: 12, 61: 7, 39: 13, 3: 5, 60: 3, 52: 19, 4: 11, 65: 13, 27: 17, 47: 17, 14: 12, 12: 14, 34: 16, 35: 14, 44: 13, 31: 8, 42: 13, 13: 15, 57: 9, 18: 10, 62: 10, 72: 4, 53: 17, 49: 11, 9: 7, 76: 11, 67: 11, 68: 6, 50: 14, 22: 11, 33: 3, 41: 6, 10: 7}) 1001\n"
          ]
        }
      ],
      "source": [
        "# dump label counts for val set\n",
        "val_label_cnt = defaultdict(int)\n",
        "for i, sample in enumerate(valset):\n",
        "  x,y = sample.raw_text, sample.label\n",
        "  if i < 2:\n",
        "    print(x, y)\n",
        "  val_label_cnt[y] += 1\n",
        "print(val_label_cnt, len(valset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LperF8_4FQle"
      },
      "source": [
        "## Part II: Feature Engineering - Bag of N-gram [25 pts]\n",
        "The first step to deal with text data is to transform them into logic structure that\n",
        "computers can \"understand\". For this problem, we will\n",
        "use the trick of Bag of N-grams. A (word-level) N-gram can be thought of as a\n",
        "continuous sequence of tokens in a document. For instance, given a document \"I\n",
        "love NLP\", if we tokenize it using space, we will have unigrams {I; love; NLP},\n",
        "a bigrams {(I; love); (love; NLP )}, and trigram {(I love nlp)}.\n",
        "\n",
        "To represent N-gram, we will first set a vocabulary base V which can be\n",
        "viewed as a set of words. Since we are limited by the available computational\n",
        "resources, we need to set a limit on the number of vocabularies we add to our\n",
        "vocabulary base. A common way to construct vocabulary base is to choose the\n",
        "top k (a hyper-parameter set by user) most frequently occurred N-grams in the\n",
        "data set.\n",
        "\n",
        "We provide you with a top-level function\n",
        "process text dataset that transforms a collection of text data points into a collection of n-gram indices. The n-gram indices are served as a sparse vector of an input document.\n",
        "Your job is to fill in the code for the\n",
        "helper functions that complete this process.\n",
        "You will find the Python Counter object very helpful in this part of the assignment.\n",
        "\n",
        "Please refer to https://docs.python.org/2/library/collections.html#collections.Counter for more info."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S25iNxpXkOZP"
      },
      "source": [
        "2.1 Extract N-gram from Text\n",
        "\n",
        "Function `def extract_ngram_from_text` takes two inputs: a raw text string text and\n",
        "an integer n which represents the max length of continuous tokens we would like\n",
        "to extract from text. For input ‘I love NLP’ and n = 2, this function should extract all unigram and bigrams tokens = {I; love; NLP; (I; love); (love; NLP )}.\n",
        "Note that in addition to tokens, this program should also output an Python\n",
        "Counter object that counts the number of occurrences for each N-gram in\n",
        "tokens. Please fill in your code to complete this function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYw1_u0ckan7"
      },
      "source": [
        "2.2 Construct Vocabulary Base\n",
        "\n",
        "Once we obtain the N-grams for each sample, we can construct our vocabulary\n",
        "base. Function `def construct_ngram_indexer` takes in two arguments ngram counter list,\n",
        "which is a collection of Python Counter mentioned in the previous problem, and\n",
        "an integer topk. This function should form a vocabulary base using the most\n",
        "common topk N-grams. Moreover, we would like to take a further step and\n",
        "create a dictionary ngram indexer that maps each N-gram in our vocabulary\n",
        "base to a unique integer that represents the N-gram’s identity. Note that index\n",
        "0 is reserved for special padding symbol which will be explained later. Please\n",
        "fill in your code to complete this function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l3ANaLkkeWu"
      },
      "source": [
        "2.3 Map N-gram to Index\n",
        "\n",
        "Lastly, function token to index takes in tokens, which is a list of N-grams,\n",
        "and ngram indexer constructed above and maps each N-gram in the list to its\n",
        "corresponding index. Please fill in your code to complete this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "E7dzFoP-FQlg"
      },
      "outputs": [],
      "source": [
        "def extract_ngram_from_text(text, n, remove_stopwords=True):\n",
        "    \"\"\"\n",
        "    Function that retrieves all n-grams from the input string\n",
        "    @param text: raw string\n",
        "    @param n: integer that tells the model to retrieve all k-gram where k<=n\n",
        "    @return ngram_counter: a counter that maps n-gram to its frequency\n",
        "    @return tokens: a list of parsed ngrams\n",
        "    \"\"\"\n",
        "    # tokenize words - for simplicity just split by space\n",
        "    #tokens = text.split(\" \")\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    if remove_stopwords:\n",
        "        tokens = [token for token in tokens if token not in english_stopwords]\n",
        "    # extract n grams\n",
        "    # TODO: replace with your code\n",
        "    ngram_counter = Counter()\n",
        "    all_ngrams = set()\n",
        "    for o in range(1, n + 1):\n",
        "        text_ngrams = nltk.ngrams(tokens, n=o, pad_left=False, pad_right=False)\n",
        "        for ngram in text_ngrams:\n",
        "            ngram_counter[ngram] += 1\n",
        "            all_ngrams.add(ngram)\n",
        "    #all_ngrams = [\"this\", \"is\", \"an\", \"ngram\"]\n",
        "    all_ngrams = list(all_ngrams)\n",
        "    #print(all_ngrams)\n",
        "    return ngram_counter, all_ngrams\n",
        "\n",
        "\n",
        "def construct_ngram_indexer(ngram_counter_list, topk):\n",
        "    \"\"\"\n",
        "    Function that selects the most common topk ngrams\n",
        "    @param ngram_counter_list: list of counters\n",
        "    @param topk, int: # of\n",
        "    @return ngram2idx: a dictionary that maps ngram to an unique index\n",
        "    \"\"\"\n",
        "    # TODO: fill in your code here\n",
        "    # find the top k ngram\n",
        "    # maps the ngram to an unique index\n",
        "    ngram_indexer = {}\n",
        "    tot_counter = Counter()\n",
        "    vocab = set()\n",
        "    i = 1\n",
        "    for counter in ngram_counter_list:\n",
        "        for ngram in counter:\n",
        "            tot_counter[ngram] += counter[ngram]\n",
        "        \n",
        "    for ngram in tot_counter.keys():\n",
        "        vocab.add(ngram)\n",
        "    ngram_indexer = {ngram : i + 1 for i, ngram in enumerate(vocab)}\n",
        "    #print(ngram_indexer)\n",
        "    return ngram_indexer\n",
        "\n",
        "def token_to_index(tokens, ngram_indexer):\n",
        "    \"\"\"\n",
        "    Function that transform a list of tokens to a list of token index.\n",
        "    @param tokens: list of ngram\n",
        "    @param ngram_indexer: a dictionary that maps ngram to an unique index\n",
        "    \"\"\"\n",
        "    # TODO: replace with your code\n",
        "    # Please DO NOT assign any ngram to index 0 which is reserved for PAD token\n",
        "    #print('tokens:', tokens)\n",
        "\n",
        "    index_list = [ngram_indexer.get(word, len(ngram_indexer.keys()) + 1) for word in tokens]\n",
        "    return index_list\n",
        "\n",
        "def process_text_dataset(dataset, n, topk=None, ngram_indexer=None):\n",
        "    \"\"\"\n",
        "    Top level function that encodes each datum into a list of ngram indices\n",
        "    @param dataset: list of Datum\n",
        "    @param n: n in \"n-gram\"\n",
        "    @param topk: #\n",
        "    @param ngram_indexer: a dictionary that maps ngram to an unique index\n",
        "    \"\"\"\n",
        "    # extract n-gram\n",
        "    for i in range(len(dataset)):\n",
        "        text_datum = dataset[i].raw_text\n",
        "        ngrams, tokens = extract_ngram_from_text(text_datum, n)\n",
        "        dataset[i].set_ngram(ngrams)\n",
        "        dataset[i].set_tokens(tokens)\n",
        "    # select top k ngram\n",
        "    if ngram_indexer is None:\n",
        "        ngram_indexer = construct_ngram_indexer([datum.ngram for datum in dataset], topk)\n",
        "        #print(ngram_indexer)\n",
        "    # vectorize each datum\n",
        "    for i in range(len(dataset)):\n",
        "        dataset[i].set_token_idx(token_to_index(dataset[i].tokens, ngram_indexer))\n",
        "    return dataset, ngram_indexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VXEJZnmpFQll"
      },
      "outputs": [],
      "source": [
        "# convert text data into list of index - should take few mins\n",
        "# Note that we are using the train_ngram_indexer to index validation and test dataset. Why?\n",
        "# Your answer:\n",
        "\n",
        "train_data, train_ngram_indexer = process_text_dataset(trainset, ngram_n, vocab_size)\n",
        "validation_data, _ = process_text_dataset(valset, ngram_n, ngram_indexer=train_ngram_indexer)\n",
        "test_data, _ = process_text_dataset(testset, ngram_n, ngram_indexer=train_ngram_indexer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oQSYirVFQlo"
      },
      "source": [
        "## Part III: Construct Input Pipeline for PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_ZfzVR_VFQlo"
      },
      "outputs": [],
      "source": [
        "class TextClassifierDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
        "    Note that this class inherits torch.utils.data.Dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_list):\n",
        "        \"\"\"\n",
        "        @param data_list: list of Datum\n",
        "        \"\"\"\n",
        "        self.data_list = data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        \"\"\"\n",
        "        Triggered when you call dataset[i]\n",
        "        \"\"\"\n",
        "        token_idx, label = self.data_list[key].token_idx, self.data_list[key].label\n",
        "        return (token_idx, len(token_idx)), label\n",
        "\n",
        "\n",
        "def text_classifier_collate_func(batch):\n",
        "    \"\"\"\n",
        "    Customized function for DataLoader that dynamically pads the batch so that all\n",
        "    data have the same length\n",
        "    \"\"\"\n",
        "    data_list = []\n",
        "    label_list = []\n",
        "    length_list = []\n",
        "    for datum in batch:\n",
        "        label_list.append(datum[1])\n",
        "        length_list.append(datum[0][1])\n",
        "    max_length = np.max(length_list)\n",
        "    # padding\n",
        "    for datum in batch:\n",
        "        padded_vec = np.pad(np.array(datum[0][0]),\n",
        "                                pad_width=((0,max_length-datum[0][1])),\n",
        "                                mode=\"constant\", constant_values=0)\n",
        "        data_list.append(padded_vec)\n",
        "\n",
        "    # return tuples and send them to device (e.g. cpu/gpu depending on availability)\n",
        "    return torch.from_numpy(np.array(data_list)).to(device), torch.LongTensor(length_list).to(device), torch.LongTensor(label_list).to(device)\n",
        "\n",
        "# consturct datasets\n",
        "py_train = TextClassifierDataset(train_data)\n",
        "py_validation = TextClassifierDataset(validation_data)\n",
        "py_test = TextClassifierDataset(test_data)\n",
        "\n",
        "# construct data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=py_train,\n",
        "                                           batch_size=batch_size,\n",
        "                                           collate_fn=text_classifier_collate_func,\n",
        "                                           shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=py_validation,\n",
        "                                           batch_size=batch_size,\n",
        "                                           collate_fn=text_classifier_collate_func,\n",
        "                                           shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=py_test,\n",
        "                                           batch_size=batch_size,\n",
        "                                           collate_fn=text_classifier_collate_func,\n",
        "                                           shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88EBH3B9FQlq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is an training sample: ([1254, 1626, 357, 1824, 1621], 5)\n",
            "This is a label: 21\n"
          ]
        }
      ],
      "source": [
        "print(\"This is an training sample: {0}\".format(py_train[0][0]))\n",
        "print(\"This is a label: {0}\".format(py_train[0][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-63YYUvFQlt"
      },
      "source": [
        "## Part IV: Define Model [15 pts]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0cZ8zmXXVUIR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(\n",
              "  (_embed): Embedding(64001, 77, padding_idx=0)\n",
              ")"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, num_class):\n",
        "    super().__init__()\n",
        "    # TODO: Your code\n",
        "    # Hint: Use nn.Embedding to store the feature weights, and set embedding_dim = num_class\n",
        "    # Note that the # of inputs dimension for embedding shall be vocab_size+1, why?\n",
        "    # In the embedding, you need to set the padding_idx argument.\n",
        "    # Please see http://pytorch.org/docs/master/nn.html\n",
        "    self._embed = nn.Embedding(num_embeddings = vocab_size + 1, embedding_dim = num_class, padding_idx = 0)\n",
        "\n",
        "  def forward(self, data, length):\n",
        "    \"\"\"\n",
        "        @param data: matrix of size (batch_size, max_length). Each row in data represents a\n",
        "            review that is represented using a list of n-gram indices.\n",
        "            In a batch, all samples are padded to have the same length.\n",
        "    \"\"\"\n",
        "    # TODO: Your code\n",
        "    # You need to calculate the sum of the activated feature weights\n",
        "    # The output of this function should be a Tensor of shape = (batch_size, num_class), i.e\n",
        "    # a batch of logits per class (No need to pass logits into Softmax here, as torch.nn.CrossEntropyLoss() takes in logits)\n",
        "    #print(data.shape)\n",
        "    output = self._embed(data)\n",
        "    #print(output.shape)\n",
        "    #output = F.sigmoid(output)\n",
        "    output = torch.sum(output, dim = 1)\n",
        "    #print(output.shape)\n",
        "    return output\n",
        "\n",
        "# instantiate a LR model\n",
        "model = LogisticRegression(vocab_size, num_class)\n",
        "# send the model to device (cpu/gpu)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2zHaoGtFQlv"
      },
      "source": [
        "## Part V: Define Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBeoAYGXFQlv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.1\n"
          ]
        }
      ],
      "source": [
        "# Loss and Optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "print(learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzAoqvIgFQlw"
      },
      "source": [
        "## Part VI: Train and Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahtxFOUS1gCu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 1831), started 1:24:46 ago. (Use '!kill 1831' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-802ab2709d4d598b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-802ab2709d4d598b\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import os\n",
        "\n",
        "logs_base_dir = \"runs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir \"runs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0hLhxmyilBR"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import sklearn.metrics\n",
        "\n",
        "# Define the test model function\n",
        "def test_model(loader, model):\n",
        "    \"\"\"\n",
        "    Help function that tests the model's performance on a dataset\n",
        "    @param: loader - data loader for the dataset to test against\n",
        "    \"\"\"\n",
        "    # set model to eval mode (no randomness (e.g. dropout) is introduced during feedforward)\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for data, lengths, labels in loader:\n",
        "        # should not compute gradient during eval to speed-up computation and reduce memory comsumption\n",
        "        with torch.no_grad():\n",
        "          logits = model(data, lengths)\n",
        "\n",
        "        all_preds.append(logits.detach().cpu().numpy())\n",
        "        all_labels.append(labels.detach().cpu().numpy())\n",
        "\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    all_logits = np.concatenate(all_preds)\n",
        "    all_pred_ids = np.argmax(all_logits, axis=-1)\n",
        "\n",
        "    # calculate metrics\n",
        "    accuracy = np.sum(all_pred_ids == all_labels) / len(all_labels)\n",
        "    precision = sklearn.metrics.precision_score(all_labels, all_pred_ids, average=\"macro\")\n",
        "    recall = sklearn.metrics.recall_score(all_labels, all_pred_ids, average = \"macro\")\n",
        "    f1 = 2.0 * precision * recall / (precision + recall)\n",
        "\n",
        "    # set model back to train model\n",
        "    model.train()\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_hvyhBeFQlw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 25 16:18:52 CST 2024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [02:34<00:00,  1.54s/it]\n"
          ]
        }
      ],
      "source": [
        "# print the timestamp (Please do not remove)\n",
        "!date\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Training the Model\n",
        "model.train()\n",
        "global_step = 0\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
        "        global_step += 1\n",
        "\n",
        "        data_batch, length_batch, label_batch = Variable(data), Variable(lengths), Variable(labels)\n",
        "        outputs = model(data_batch, length_batch)\n",
        "        #print(label_batch)\n",
        "        #print(label_batch)\n",
        "        if i == 0:\n",
        "            #print(list(model.parameters()))\n",
        "            pass\n",
        "        loss = criterion(outputs, label_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # report performance in tensorboard\n",
        "        if (i+1) % (batch_size*4) == 0:\n",
        "            val_acc, val_precision, val_recall, val_f1 = test_model(validation_loader, model)\n",
        "#            print('Epoch: [{0}/{1}], Step: [{2}/{3}], Loss: {4}, Validation Acc:{5}'.format(\n",
        "#                   epoch+1, num_epochs, i+1, len(py_train)//batch_size, loss.data, val_acc))\n",
        "            writer.add_scalar(\"Loss/train\", loss.item(), global_step)\n",
        "            writer.add_scalar(\"Acc/dev\", val_acc, global_step)\n",
        "            writer.add_scalar(\"Precision/dev\", val_precision, global_step)\n",
        "            writer.add_scalar(\"Recall/dev\", val_recall, global_step)\n",
        "            writer.add_scalar(\"F1/dev\", val_f1, global_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfoCO2SzFQlx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 25 16:21:30 CST 2024\n",
            "(0.8045454545454546, 0.8105016576575053, 0.8045454545454545, 0.8075125730300747)\n"
          ]
        }
      ],
      "source": [
        "# print the timestamp (Please do not remove)\n",
        "!date\n",
        "\n",
        "\n",
        "\n",
        "# Test the Model\n",
        "print(test_model(test_loader, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL-cK5yahDcL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 25 16:21:37 CST 2024\n",
            "odict_keys(['_embed.weight'])\n"
          ]
        }
      ],
      "source": [
        "# print the timestamp (Please do not remove)\n",
        "!date\n",
        "\n",
        "state_dict = model.state_dict()\n",
        "print(state_dict.keys())\n",
        "torch.save(state_dict, \"pytorch_model.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tSKFCS1osTJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 25 16:21:50 CST 2024\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print the timestamp (Please do not remove)\n",
        "!date\n",
        "\n",
        "# read state dict (each parameter has a name that maps to a tensor)\n",
        "state_dict = torch.load(\"pytorch_model.bin\", map_location=\"cpu\")\n",
        "\n",
        "# load weights into model\n",
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1L0c1Dpo2rQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 25 16:21:52 CST 2024\n",
            "(0.8045454545454546, 0.8105016576575053, 0.8045454545454545, 0.8075125730300747)\n"
          ]
        }
      ],
      "source": [
        "# print the timestamp (Please do not remove)\n",
        "!date\n",
        "\n",
        "# Test the loaded model from Google Drive\n",
        "print(test_model(test_loader, model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r8UCbDSFQlz"
      },
      "source": [
        "## Part VII: Parameter Tuning [10 *pts*]\n",
        "\n",
        "### Try `ngram_n=2` [5 *pts*]\n",
        "Try to optimize your model F1 performance based on the validation set.\n",
        "Then report your precision/recall/F1 on both validation and test sets.\n",
        "What do you discover?\n",
        "\n",
        "### Other hyper-parameter tuning [5 *pts*]\n",
        "Pick one other hyper-parameter to tune on. Which one will you pick?\n",
        "Then report your precision/recall/F1 on both validation and test sets.\n",
        "What do you discover?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vwOo5EJuXip"
      },
      "source": [
        "Your code & answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI2HNJdHuYwR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb 25 16:37:11 CST 2024\n"
          ]
        }
      ],
      "source": [
        "# print the timestamp (please do not remove)\n",
        "!date\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In **2gram.ipynb**, I modified the 1gram model to 2gram model, and the model performs worse on all the metrics (accuracy, precision, recall, f1), dropping from 0.8 to 0.7. I suspect this is because this text classification task can be done quite well by checking certain key words (i.e., 1-gram model), and applying 2-gram negatively impacts the focus on these keywords. 1-gram may be a good choice for this discriminative model, whereas high-order n-grams will certainly perform better in generative models.\n",
        "\n",
        "In **lr_tuning.ipynb**, I modified the learning rate from 0.1 to 0.01, and the model's performance drops from 0.8 to 0.6. I conjecture this is because smaller learning rate makes the model converge slower. If the model is trained for more epochs, perhaps the model can achieve comparable performance to the one with 0.1 learning rate.\n",
        "\n",
        "However, this conjecture is not validated, as I trained the model for 200 epochs, but the performance does not improved considerably. Therefore, there may be some other factors that spoil the model performance when learning rate is smaller."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.9 ('myenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "cf1ee045094a7edcaf157dc10598d3c573f589dd9a2b2fe8dfda33b9ea61c786"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "032f847d06494ba89d75e2bb04b6f816": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45fb69c53b3d498899e2ba0aa1cd4b74",
            "placeholder": "​",
            "style": "IPY_MODEL_d956397732b74785abafa2b04c2f78f0",
            "value": " 262k/262k [00:00&lt;00:00, 2.87MB/s]"
          }
        },
        "0afa528dfa6e466c8c770fb715bdf7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1bd913aafa24aa9a66fb8788ef725db",
            "placeholder": "​",
            "style": "IPY_MODEL_851670b1d0cd4bd9a04531c597de65a9",
            "value": "Generating train split: "
          }
        },
        "14250df929f240bdaae083b2d4fee179": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f977764c671b460eacd89d8e577a0ebc",
            "max": 261699,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6446102077754fe99411d837a5d95b7a",
            "value": 261699
          }
        },
        "1c3b5dc0a92741b7a4220947a21c3a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2003fe223063495c8ab909cb450d482c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "225cafeb1683440b8c56cebcf5176a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_246e08963f1e42c0827a0b6bcf1d8020",
            "placeholder": "​",
            "style": "IPY_MODEL_290f947a094346f6bd61c65d14ac5c86",
            "value": "Downloading data: 100%"
          }
        },
        "246e08963f1e42c0827a0b6bcf1d8020": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27ca92810a5e40c9b1dbbae2c98a62f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "28126a98dd674352a5f39c458e5726e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "290f947a094346f6bd61c65d14ac5c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "314f4dc695934b0abac326ece02f3036": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc11d7cc3d8148b8a2c10e21cb419bad",
            "placeholder": "​",
            "style": "IPY_MODEL_28126a98dd674352a5f39c458e5726e3",
            "value": " 2.96M/2.96M [00:01&lt;00:00, 2.72MB/s]"
          }
        },
        "32c92f30bcaf4328a048dda7327bc15c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33875da710664c689a91c2a61e043c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3424d6c236d84d6f8a4a4af1a6727ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2003fe223063495c8ab909cb450d482c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3de2ddb357344862b70205b2e922b088",
            "value": 1
          }
        },
        "37f993fdfead46eca86fbbc0a1c6c7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1b9c52c9f204f23b982c546cca4a5bd",
              "IPY_MODEL_438184da8742414690c0701f13cc63e0",
              "IPY_MODEL_38bdd891d2c549288e62400af5a868d6"
            ],
            "layout": "IPY_MODEL_cb6e3aa3b0c848e0a85ae58ce99e2165"
          }
        },
        "38bdd891d2c549288e62400af5a868d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f9d9fd7a434da388c3b4d854f38c15",
            "placeholder": "​",
            "style": "IPY_MODEL_750807425efa4f31b2ed2b4e2d545ccd",
            "value": " 236k/236k [00:00&lt;00:00, 4.28MB/s]"
          }
        },
        "3de2ddb357344862b70205b2e922b088": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "438184da8742414690c0701f13cc63e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f79fb4014ba4e18bd11cb9c8385727f",
            "max": 235756,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6298823d67b74b27903207eb82c40089",
            "value": 235756
          }
        },
        "45fb69c53b3d498899e2ba0aa1cd4b74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "519490b9c61a45fcaf9ca30fb98b3ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58c64d5a28734da9bcb88b4d76ebbd5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebf3244702b3476fbeaf7f659852d05d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6830e40963224a95af9afc2b5f558731",
            "value": 1
          }
        },
        "5b93033e0fa64a2589d043359463c787": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c46fe678117498abf4fec3a63042efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6298823d67b74b27903207eb82c40089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62fee8e94fe44b39882767e9d0833647": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a827c81ef3ce4264ba578489d2c15ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_ec8bd89b0aa549f38c782ced72166fc4",
            "value": " 3370/0 [00:00&lt;00:00, 80263.50 examples/s]"
          }
        },
        "6338deac29274431bfa21e8fdb908378": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adcbf968d503466e94bd0996e698dcc1",
            "placeholder": "​",
            "style": "IPY_MODEL_519490b9c61a45fcaf9ca30fb98b3ca8",
            "value": " 42068/0 [00:00&lt;00:00, 407552.02 examples/s]"
          }
        },
        "6446102077754fe99411d837a5d95b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6830e40963224a95af9afc2b5f558731": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ec9825fd1bc4b71a63d8245b5ec0dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7ff0e8ec8ce4f5aad9df6f201cfc234",
              "IPY_MODEL_3424d6c236d84d6f8a4a4af1a6727ecc",
              "IPY_MODEL_62fee8e94fe44b39882767e9d0833647"
            ],
            "layout": "IPY_MODEL_83a61a7f8bd946179c1bce59f3dad52a"
          }
        },
        "750807425efa4f31b2ed2b4e2d545ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f5f28c95840437db9d8e1d674c1d551": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27ca92810a5e40c9b1dbbae2c98a62f7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e5dc2128cb7497dbafd6cb943c67b0c",
            "value": 1
          }
        },
        "81188557c7c7485a995da290abc91e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a61a7f8bd946179c1bce59f3dad52a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83f78ed4b7834c90b122ec6372df8b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0afa528dfa6e466c8c770fb715bdf7f5",
              "IPY_MODEL_58c64d5a28734da9bcb88b4d76ebbd5a",
              "IPY_MODEL_6338deac29274431bfa21e8fdb908378"
            ],
            "layout": "IPY_MODEL_b31b6bd4f5aa45afa89a90454ec8e7ed"
          }
        },
        "851670b1d0cd4bd9a04531c597de65a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d544bacd73d4fa2b67d18eeda77e3ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e5dc2128cb7497dbafd6cb943c67b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f0f4e1c86ec414f88ae27a4dc971098": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdb73ab8b02f42f38024f1a34c002c10",
              "IPY_MODEL_a8c853d6856c4c5496fcbcee027b9588",
              "IPY_MODEL_314f4dc695934b0abac326ece02f3036"
            ],
            "layout": "IPY_MODEL_c05ff0791d9e4aabab70d4c9c38f49cc"
          }
        },
        "9f79fb4014ba4e18bd11cb9c8385727f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1553160957c4fc0a77329eaa7ead63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2133356ddc746b6ae578ca290b1167e",
              "IPY_MODEL_7f5f28c95840437db9d8e1d674c1d551",
              "IPY_MODEL_d8483392e73e4c789becb519dfc3b330"
            ],
            "layout": "IPY_MODEL_ed9144f0aa194605b00c60567c4794a6"
          }
        },
        "a2133356ddc746b6ae578ca290b1167e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8cb5168b143442f8b5e298199a7936b",
            "placeholder": "​",
            "style": "IPY_MODEL_efe11a12fee04deabefa51935993f073",
            "value": "Generating test split: "
          }
        },
        "a827c81ef3ce4264ba578489d2c15ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8c853d6856c4c5496fcbcee027b9588": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d544bacd73d4fa2b67d18eeda77e3ae",
            "max": 2961439,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f873281c739741f89d268ad4b1b130c8",
            "value": 2961439
          }
        },
        "a9f9d9fd7a434da388c3b4d854f38c15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adcbf968d503466e94bd0996e698dcc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9c70857fd4461c9275e64d2edf7060": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b31b6bd4f5aa45afa89a90454ec8e7ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8cb5168b143442f8b5e298199a7936b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc11d7cc3d8148b8a2c10e21cb419bad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c05ff0791d9e4aabab70d4c9c38f49cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b9c52c9f204f23b982c546cca4a5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9c70857fd4461c9275e64d2edf7060",
            "placeholder": "​",
            "style": "IPY_MODEL_5c46fe678117498abf4fec3a63042efc",
            "value": "Downloading data: 100%"
          }
        },
        "c1bd913aafa24aa9a66fb8788ef725db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb6e3aa3b0c848e0a85ae58ce99e2165": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ff0e8ec8ce4f5aad9df6f201cfc234": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81188557c7c7485a995da290abc91e4c",
            "placeholder": "​",
            "style": "IPY_MODEL_5b93033e0fa64a2589d043359463c787",
            "value": "Generating validation split: "
          }
        },
        "d8483392e73e4c789becb519dfc3b330": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c92f30bcaf4328a048dda7327bc15c",
            "placeholder": "​",
            "style": "IPY_MODEL_de1cab1f50df4c72a08c88ef84c467f0",
            "value": " 3761/0 [00:00&lt;00:00, 86662.22 examples/s]"
          }
        },
        "d956397732b74785abafa2b04c2f78f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de1cab1f50df4c72a08c88ef84c467f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e28d4b71cde54919979976989a6b9f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_225cafeb1683440b8c56cebcf5176a30",
              "IPY_MODEL_14250df929f240bdaae083b2d4fee179",
              "IPY_MODEL_032f847d06494ba89d75e2bb04b6f816"
            ],
            "layout": "IPY_MODEL_f230dfbb592a4e569293ea556b289c4d"
          }
        },
        "ebf3244702b3476fbeaf7f659852d05d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ec8bd89b0aa549f38c782ced72166fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed9144f0aa194605b00c60567c4794a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efe11a12fee04deabefa51935993f073": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f230dfbb592a4e569293ea556b289c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f873281c739741f89d268ad4b1b130c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f977764c671b460eacd89d8e577a0ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb73ab8b02f42f38024f1a34c002c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33875da710664c689a91c2a61e043c2f",
            "placeholder": "​",
            "style": "IPY_MODEL_1c3b5dc0a92741b7a4220947a21c3a5c",
            "value": "Downloading data: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
